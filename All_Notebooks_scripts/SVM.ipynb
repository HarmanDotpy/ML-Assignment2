{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "numcat = 2\n",
    "categories = ['healthy', 'disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  restbps  chol  category\n",
      "0   26      109   243         0\n",
      "1   27      106   156         0\n",
      "2   28      107   225         0\n",
      "3   27      105   277         0\n",
      "4   30       96   221         0\n",
      "(211, 3) (211,) (489, 3) (489,)\n"
     ]
    }
   ],
   "source": [
    "df_h = pd.read_csv('health_data.csv')\n",
    "print(df_h.head())\n",
    "\n",
    "train_per = 0.7 #train test split\n",
    "#randomize indces, take the first 80% of the indeces and last 20 percent as test\n",
    "indices = np.random.permutation(df_h.shape[0])\n",
    "train_ind, test_ind = indices[:int(train_per*df_h.shape[0])], indices[int(train_per*df_h.shape[0]):]\n",
    "# print(len(train_ind), len(test_ind))\n",
    "\n",
    "#select the data corresponding to the train and test indices and save into 2 dataframes. Reset index afterwards\n",
    "train_df, test_df = df_h.loc[train_ind, :], df_h.loc[test_ind, :]\n",
    "train_df, test_df = train_df.reset_index(drop = True), test_df.reset_index(drop = True)\n",
    "# train_df.drop('index')\n",
    "\n",
    "# Data in numpy arrays (also separating train data by classes)\n",
    "X_train = train_df.drop('category', axis = 1).to_numpy()\n",
    "y_train = train_df.drop(['age', 'restbps', 'chol'], axis = 1).to_numpy().reshape((X_train.shape[0],))\n",
    "\n",
    "# X_train_0, X_train_1 = train_df.loc[train_df['category'] == 0].drop('category', axis = 1).to_numpy(),train_df.loc[train_df['category'] == 1].drop('category', axis = 1).to_numpy()\n",
    "X_test, y_test = test_df.drop('category', axis = 1).to_numpy(), test_df['category'].to_numpy().reshape((-1, ))\n",
    "print(X_test.shape, y_test.shape, X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM_solver():\n",
    "    def __init__(self, ker_type = 'linear', itermax = 1000, C= 10, epsilon = 0.0001, gamma = 10, poly = 1):\n",
    "        self.kernel_type = ker_type\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "        self.gamma = gamma\n",
    "        self.kernels = {'linear': self.k_linear, 'gaussian': self.k_gaussian, 'polynomial': self.k_polynomial}\n",
    "        self.itermax = itermax\n",
    "        self.poly = poly\n",
    "        self.gamma = gamma\n",
    "    \n",
    "    def solve_SVM(self, X, y):\n",
    "#         X.shape = (N, D) y.shape = (N,)\n",
    "        N = X.shape[0]\n",
    "        self.X = X\n",
    "        y = 2*y-1\n",
    "#         print(y)\n",
    "        self.y = y\n",
    "#         print(self.y)\n",
    "#         print(self.y)\n",
    "        K = self.get_ker_mat(self.X, y, self.kernels[self.kernel_type])\n",
    "        \n",
    "        #initializing mu's and b\n",
    "        mu = np.zeros(N)\n",
    "        b = 0\n",
    "        \n",
    "        for count in range(self.itermax):\n",
    "            #outer loop, currently just looping over the all the mu's but some heuristics\n",
    "            #can be used for selecting good values of mu_i's and mu_j's\n",
    "            \n",
    "            #saving the old values of mu to check for convergence\n",
    "            mu_old = np.copy(mu)\n",
    "\n",
    "            for i in range(N):\n",
    "#                 print(b)\n",
    "                xi, yi = X[i,:], y[i]\n",
    "                E_i = self.calc_E(y, yi, mu, b, K[i])\n",
    "                if(self.KKTviolate(mu[i], E_i, yi) == True):\n",
    "                    j = self.choose_random(0, N, i)\n",
    "                    mu_i_old, mu_j_old = np.copy(mu[i]), np.copy(mu[j])\n",
    "\n",
    "                    xj, yj = X[j,:], y[j]\n",
    "                    E_j = self.calc_E(y, yj, mu, b, K[j])\n",
    "                    L, H = self.getLH(yi, yj, mu[i], mu[j], self.C)\n",
    "                    \n",
    "                    #skip if L and H are same\n",
    "                    if(L == H):\n",
    "                        continue\n",
    "                    \n",
    "                    eta = 2*K[i, j]-K[i, i]-K[j, j]\n",
    "#                     print(eta)\n",
    "                    if(eta==0):\n",
    "                        continue\n",
    "#                     print(eta)\n",
    "                    mu[j] = mu_j_old - yj*(E_i-E_j)/eta\n",
    "#                     print('eta = {}'.format(eta))\n",
    "                    mu[j] = self.clip(L, mu[j] , H)\n",
    "                    \n",
    "                    #if not much change in mu_j then donot update this i\n",
    "                    if(np.absolute(mu[j] - mu_j_old)<1e-5):\n",
    "                        continue\n",
    "                    \n",
    "                    mu[i] = mu_i_old + yi*yj*(mu_j_old - mu[j])\n",
    "                    b = self.get_b(b, E_i, E_j, yi, yj, xi, xj, K[i, i], K[j, j], K[i, j], mu[j], mu_j_old, mu[i], mu_i_old)\n",
    "            \n",
    "            \n",
    "            #convergence criteria\n",
    "#             if(np.absolute(mu_old - mu).sum() <= self.epsilon):\n",
    "#                 break\n",
    "                \n",
    "            if(count%100==0):\n",
    "                print('iteration number = {}'.format(count))\n",
    "        return mu, b\n",
    "    \n",
    "    def get_ker_mat(self, X, y, Kernel):\n",
    "        mat = np.zeros((X.shape[0], X.shape[0]))\n",
    "        for i in range(X.shape[0]):\n",
    "            for j in range(X.shape[0]):\n",
    "                mat[i, j] = Kernel(X[i], X[j])\n",
    "        return mat\n",
    "    \n",
    "    def get_b(self, b, E_i, E_j, yi, yj, xi, xj, Ki, Kj, Kij, mu_j_new, mu_j_old, mu_i_new, mu_i_old):\n",
    "        b1 = b - E_i - yi*(mu_i_new-mu_i_old)*Ki - yj*(mu_j_new-mu_j_old)*Kij\n",
    "        b2 = b - E_j - yj*(mu_j_new-mu_j_old)*Kj - yi*(mu_i_new-mu_i_old)*Kij\n",
    "        \n",
    "        if(mu_i_new<self.C and mu_i_new>0):\n",
    "            b = b1\n",
    "        elif(mu_j_new<self.C and mu_j_new>0):\n",
    "            b = b2\n",
    "        else:\n",
    "            b = (b1+b2)/2\n",
    "        return b\n",
    "        \n",
    "    \n",
    "    def clip(self, L, mu, H):\n",
    "#         print('mu = {}, clipmu = {}'.format(mu, np.clip(mu, L, H)))\n",
    "        return np.clip(mu, L, H)        \n",
    "    \n",
    "    def getLH(self, yi, yj, mui, muj, c):\n",
    "        if(yi!=yj):\n",
    "            return max(0, muj-mui), min(c, c+muj-mui)\n",
    "        if(yi==yj):\n",
    "            return max(0, muj+mui-c), min(c, muj+mui)\n",
    "        \n",
    "    \n",
    "    def choose_random(self, l, h, i):\n",
    "        random = i\n",
    "        \n",
    "        while(random == i):\n",
    "            random = np.random.randint(l, h)\n",
    "        \n",
    "        return random\n",
    "    \n",
    "    def KKTviolate(self, mui, Ei, yi):\n",
    "        if((Ei*yi<-1*1e-5 and mui<self.C) or (Ei*yi > 1e-5 and mui>0)):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    \n",
    "    def calc_E(self, y, yi, mu, b, Ki):\n",
    "        assert(y.shape == mu.shape == Ki.shape)\n",
    "        f = np.sum(mu*y*Ki) + b\n",
    "        \n",
    "        return f-yi  \n",
    "    \n",
    "    def k_linear(self, x1, x2):\n",
    "#         print(x1.shape)\n",
    "        return np.sum(x1*x2)\n",
    "        \n",
    "    def k_gaussian(self, x1, x2):\n",
    "        return np.exp(-self.gamma*np.sum((x1 - x2)**2))\n",
    "        \n",
    "    def k_polynomial(self, x1, x2):\n",
    "        return (1+np.sum(x1*x2))**self.p\n",
    "    \n",
    "    def get_kermat_test(self, X_test, X_train):\n",
    "        mat = np.zeros((X_test.shape[0], X_train.shape[0]))\n",
    "        Kernel = self.kernels[self.kernel_type]\n",
    "        for i in range(X_test.shape[0]):\n",
    "            for j in range(X_train.shape[0]):\n",
    "                mat[i, j] = Kernel(X_test[i], X_train[j])\n",
    "        return mat\n",
    "    \n",
    "    def predict(self, X_test, mu, b):\n",
    "        yhat = np.zeros((X_test.shape[0]))\n",
    "        k_test_mat = self.get_kermat_test(X_test, self.X)\n",
    "        for i in range(X_test.shape[0]):\n",
    "            fi = np.sum(mu*self.y*k_test_mat[i]) + b\n",
    "            if(fi<0):\n",
    "                yhat[i] = 0\n",
    "            else:\n",
    "                yhat[i] = 1\n",
    "        return yhat\n",
    "\n",
    "#     def getK():\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration number = 0\n",
      "iteration number = 100\n",
      "iteration number = 200\n",
      "iteration number = 300\n",
      "iteration number = 400\n",
      "iteration number = 500\n",
      "iteration number = 600\n",
      "iteration number = 700\n",
      "iteration number = 800\n",
      "iteration number = 900\n"
     ]
    }
   ],
   "source": [
    "#Note for RBF KERNEL gamma = 1/2sigma^2\n",
    "svm_model = SVM_solver(ker_type = 'linear', itermax = 1000, C = 1, epsilon = 0.001, gamma = 1, poly = 1)# gamma will only be used for the gaussian kernel\n",
    "mu, b = svm_model.solve_SVM(X_train, y_train)\n",
    "y_hat_test = svm_model.predict(X_test, mu, b)\n",
    "# get_stats(y_hat_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8625592417061612\n"
     ]
    }
   ],
   "source": [
    "# print(y_hat_test)\n",
    "print((y_hat_test==y_test).sum()/(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_hat_train = svm_model.predict(X_train, mu, b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((y_hat_train==y_train).sum()/(y_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(y_hat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(mu, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of LibSVM and SMO algorithm implemented above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf')\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8720379146919431\n"
     ]
    }
   ],
   "source": [
    "print((y_pred_test==y_test).sum()/(y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
