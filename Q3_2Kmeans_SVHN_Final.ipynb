{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Q3-2Kmeans-SVHN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOn03+iyhb9BA8WnRSP054V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c2e9d09a59d74f0d84dfb366ac0153ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2fcacdb433dd40efb7ac530580521fec",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bde0a985dbb24d25ad27c243bdfddbc6",
              "IPY_MODEL_c0301ae8e32c4f6eabf605a6382e77e7"
            ]
          }
        },
        "2fcacdb433dd40efb7ac530580521fec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bde0a985dbb24d25ad27c243bdfddbc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b5a136472d64a84906d2becad8f4ac4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3bd52d7c88541eea81cc0b15291f58e"
          }
        },
        "c0301ae8e32c4f6eabf605a6382e77e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_85d4f8a469e5482b99f33ca0ecbcea06",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 182042624/? [00:30&lt;00:00, 18741398.03it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ede59c7414b74afdae1c8835283d0fdb"
          }
        },
        "6b5a136472d64a84906d2becad8f4ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3bd52d7c88541eea81cc0b15291f58e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "85d4f8a469e5482b99f33ca0ecbcea06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ede59c7414b74afdae1c8835283d0fdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarmanDotpy/ML-Assignment2/blob/main/Q3_2Kmeans_SVHN_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6-F5-f-Zzq1"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import sklearn as sk\r\n",
        "from sklearn import datasets\r\n",
        "from sklearn import svm\r\n",
        "from sklearn import metrics\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "from sklearn.model_selection import cross_validate\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from torchvision.datasets import SVHN\r\n",
        "import torch\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch.utils.data import ConcatDataset\r\n",
        "from torch.utils.data import random_split\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import pandas as pd\r\n",
        "import seaborn as sb\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision.datasets import SVHN\r\n",
        "from torchvision.transforms import ToTensor\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from torchvision.utils import make_grid\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJJaIS68uYVf"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksl4vzQ9QoRn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3258b176-9fb6-4c07-d2ea-54d1d00445dd"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "device"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4I3AbWbcUkP"
      },
      "source": [
        "def performance_metrics_multiclass(y_pred_test, y_test, num_class, disp_conf = True):\r\n",
        "    '''gives the TPR, FPR, acc, precision, recall and F1 score for all classes by comparing the 2 input arrays'''\r\n",
        "    #First we calculate the confusion matrix of size num_class*num_class\r\n",
        "    #NOTE: Y axis of matrix will be predicted class and x axis wll be true class\r\n",
        "    conf_mat = np.zeros((num_class, num_class))\r\n",
        "    \r\n",
        "    for i in range(num_class):\r\n",
        "        for j in range(num_class):\r\n",
        "            conf_mat[i, j] = np.logical_and(y_pred_test == i, y_test ==j).sum()\r\n",
        "    # Calculating precision, recall, F1 Score for each class\r\n",
        "    colnames = ['class', 'Precision', 'Recall', 'F1']\r\n",
        "    df = pd.DataFrame(columns = colnames)\r\n",
        "    for i in range(num_class):\r\n",
        "        TP = conf_mat[i, i]\r\n",
        "        FP = conf_mat[i].sum() - conf_mat[i, i]\r\n",
        "        TN = conf_mat.sum() - conf_mat[i].sum() - conf_mat[:, i].sum() +  conf_mat[i, i]\r\n",
        "        FN = conf_mat[:, i].sum() - conf_mat[i, i]\r\n",
        "        P = round((TP)/(TP+FP), 5)\r\n",
        "        R = round((TP)/(TP+FN), 5)\r\n",
        "        F1 = round(2*P*R/(P+R), 5)\r\n",
        "        df = df.append({'class':categories[i], 'Precision':P, 'Recall':R, 'F1':F1 }, ignore_index = True)\r\n",
        "    macroF1 = round(df['F1'].mean(), 5)\r\n",
        "    accuracy = round((y_pred_test==y_test).mean(), 5)\r\n",
        "    \r\n",
        "    # NOTE : returning the transpose of the confusion matricx to get true labels on the y axis\r\n",
        "    conf_mat = conf_mat.T\r\n",
        "    # NORMALIZING the confusion matrix\r\n",
        "    conf_mat = np.around(conf_mat/(conf_mat.sum(axis = 1)), decimals = 5)\r\n",
        "    # print(conf_mat.shape)\r\n",
        "    \r\n",
        "    #PLot the matrix if disp_conf = True\r\n",
        "    if(disp_conf == True):\r\n",
        "        ax = sb.heatmap(conf_mat, vmin = 0, vmax = 1, cmap = sb.light_palette(\"seagreen\", as_cmap=True), xticklabels = categories, yticklabels = categories, annot = True, annot_kws={\"size\": 12}, fmt=\".3f\")\r\n",
        "    #     ax.figure.axes[-1].yaxis.label.set_size(12)\r\n",
        "        plt.xlabel('Predicted Labels', fontsize = 14)\r\n",
        "        plt.ylabel('True Labels', fontsize = 14)\r\n",
        "        plt.tick_params(axis='both', labelsize=10)\r\n",
        "        return conf_mat, df, macroF1, accuracy, plt\r\n",
        "    \r\n",
        "    return conf_mat, df, macroF1, accuracy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9Cmi13FcVS2"
      },
      "source": [
        "Loading files containgin pca data of mnist and svhn , pca performed on fuilll dataset.\r\n",
        "also loading tsne files.tsne had been performed on 10k images of svhn and 20k images of mnist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHsB3tRYalxF"
      },
      "source": [
        "svhn_tsne = np.load('/content/svhn_tsne_numpy.npy')\r\n",
        "svhn_pca = np.load('/content/svhn_pca4D_numpy.npy')\r\n",
        "mnist_tsne = np.load('/content/mnist_tsne_numpy.npy')\r\n",
        "mnist_pca = np.load('/content/mnist_pca4D_numpy.npy')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLcpSbNnkfU2",
        "outputId": "1934d3a7-424e-4142-b1b2-3cc30e6c820f"
      },
      "source": [
        "print(svhn_tsne.shape, mnist_tsne.shape, svhn_pca.shape, mnist_pca.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 2) (20000, 2) (73257, 4) (60000, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdi2Aj0slQw9"
      },
      "source": [
        "clusters = [3, 5, 10, 15, 20]\r\n",
        "kmeans_svhn_tsne = {}\r\n",
        "kmeans_svhn_pca = {}\r\n",
        "kmeans_mnist_tsne = {}\r\n",
        "kmeans_mnist_pca = {}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku3odx8ukw1E"
      },
      "source": [
        "for num in clusters:\r\n",
        "  kmeans_svhn_tsne[num] = KMeans(n_clusters=num, random_state=0).fit(svhn_tsne)\r\n",
        "  kmeans_svhn_pca[num] = KMeans(n_clusters=num, random_state=0).fit(svhn_pca)\r\n",
        "  kmeans_mnist_tsne[num] = KMeans(n_clusters=num, random_state=0).fit(mnist_tsne)\r\n",
        "  kmeans_mnist_pca[num] = KMeans(n_clusters=num, random_state=0).fit(mnist_pca)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_lzjj5ymVP8",
        "outputId": "83372cc1-c1a0-4e44-d3e9-5cf0a933745c"
      },
      "source": [
        "print(kmeans_svhn_tsne[3].labels_, kmeans_svhn_tsne[3].labels_.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0 0 ... 0 0 2] (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC14u4iKq6E5"
      },
      "source": [
        "def normalize(data_tensor):\r\n",
        "    '''re-scale image values to [-1, 1]'''\r\n",
        "    return (data_tensor / 255.) * 2. - 1. \r\n",
        "    \r\n",
        "transform_list = [transforms.ToTensor(), transforms.Lambda(lambda x: normalize(x))]\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzwBSi95q6pu"
      },
      "source": [
        "Classifier using 10k data and labels from SVHN tsne performed on 10k data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c2e9d09a59d74f0d84dfb366ac0153ca",
            "2fcacdb433dd40efb7ac530580521fec",
            "bde0a985dbb24d25ad27c243bdfddbc6",
            "c0301ae8e32c4f6eabf605a6382e77e7",
            "6b5a136472d64a84906d2becad8f4ac4",
            "a3bd52d7c88541eea81cc0b15291f58e",
            "85d4f8a469e5482b99f33ca0ecbcea06",
            "ede59c7414b74afdae1c8835283d0fdb"
          ]
        },
        "id": "dJGyKAD6nh6U",
        "outputId": "be1ee90c-301c-4c62-c4ab-33c4e173a89e"
      },
      "source": [
        "dataset = SVHN(root='data/', download=True,transform=transforms.Compose(transform_list))\r\n",
        "# print(dataset.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to data/train_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2e9d09a59d74f0d84dfb366ac0153ca",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StI9R2tUtSCZ"
      },
      "source": [
        "data_loader = DataLoader(dataset, batch_size = 10000, shuffle=True, num_workers=4, pin_memory=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drH_zAABr2sP",
        "outputId": "4fcfc51d-4e29-4a19-ef5d-ad99ea90258a"
      },
      "source": [
        "X = next(iter(data_loader))[0]\r\n",
        "# y_original\r\n",
        "y = torch.Tensor(kmeans_svhn_tsne[3].labels_)\r\n",
        "print(X.shape, y.shape)\r\n",
        "X_train = X[:8000]\r\n",
        "y_train = y[:8000]\r\n",
        "X_test = X[8000:]\r\n",
        "y_test = y[8000:]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10000, 3, 32, 32]) torch.Size([10000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaCtcYD6sW_s"
      },
      "source": [
        "dataset_train = TensorDataset(X_train, y_train)\r\n",
        "dataset_test = TensorDataset(X_test, y_test)\r\n",
        "train_loader = DataLoader(dataset_train, batch_size = 128, shuffle = True, num_workers = 4, pin_memory = True)\r\n",
        "test_loader = DataLoader(dataset_test, batch_size = X_test.shape[0], shuffle = True, num_workers = 4, pin_memory = True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9NzL9EmpVjF"
      },
      "source": [
        "# Our Neural Network classifier for svhn dataset - LENET_Like architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbsRypI_pZW8"
      },
      "source": [
        "class LeNet_Like(nn.Module):\r\n",
        "\r\n",
        "    # network structure\r\n",
        "    def __init__(self):\r\n",
        "        super(LeNet_Like, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(3, 32, 5, padding=0)\r\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5)\r\n",
        "        self.fc1   = nn.Linear(64*5*5, 1200)\r\n",
        "        self.fc2   = nn.Linear(1200, 84)\r\n",
        "        self.fc3   = nn.Linear(84, 3)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\r\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2, 2))\r\n",
        "        x = x.view(-1, self.num_flat_features(x))\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "    def num_flat_features(self, x):\r\n",
        "        size = x.size()[1:]\r\n",
        "        return np.prod(size)\r\n",
        "\r\n",
        "class ConvNet(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(ConvNet, self).__init__()\r\n",
        "    self.layer1 = nn.Sequential(\r\n",
        "        nn.Conv2d(3, 32, kernel_size = 5, stride = 1, padding = 0),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(kernel_size = 2,stride = 2)\r\n",
        "        )\r\n",
        "    self.layer2 = nn.Sequential(\r\n",
        "        nn.Conv2d(32, 64,kernel_size = 5, stride = 1, padding = 2),\r\n",
        "        nn.ReLU(),\r\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\r\n",
        "        )\r\n",
        "    self.drop_out = nn.Dropout()\r\n",
        "    self.fc1 = nn.Linear(7*7*64,1000)\r\n",
        "    self.fc2 = nn.Linear(1000, 3)\r\n",
        "    # self.softmax = nn.Softmax(dim = 0)\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "    out = self.layer1(x)\r\n",
        "    out = self.layer2(out)\r\n",
        "    out = out.reshape(out.size(0), -1)    \r\n",
        "    out = self.drop_out(out)\r\n",
        "    out = self.fc1(out)\r\n",
        "    out = self.fc2(out)\r\n",
        "    # out = self.softmax(out)\r\n",
        "\r\n",
        "    return out"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W3jRTebQX1W"
      },
      "source": [
        "# X_train_, y_train_ = svhn_tsne[0:8000], y[0:8000]\r\n",
        "# X_test_, y_test_ = svhn_tsne[8000:], y[8000:]\r\n",
        "# # X_train = \r\n",
        "\r\n",
        "# dataset_train = TensorDataset(X_train_, y_train_)\r\n",
        "# dataset_test = TensorDataset(X_test_, y_test_)\r\n",
        "# train_loader = DataLoader(dataset_train, batch_size = 128, shuffle = True, num_workers = 4, pin_memory = True)\r\n",
        "# test_loader = DataLoader(dataset_test, batch_size = X_test_.shape[0], shuffle = True, num_workers = 4, pin_memory = True)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlTi34nA1e7I"
      },
      "source": [
        "categories = ['{}'.format(i) for i in range(3)]\r\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smi3s1r-tGAY",
        "outputId": "969dd09b-762f-4269-de15-1baa0e4c0799"
      },
      "source": [
        "#  initializing the model\r\n",
        "# model = LeNet_Like()\r\n",
        "model = ConvNet()\r\n",
        "model = model.to(device)\r\n",
        "criterion = nn.MSELoss(reduce = True)\r\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\r\n",
        "for name, param in model.named_parameters():\r\n",
        "    print(name, param.size(), param.requires_grad)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "layer1.0.weight torch.Size([32, 3, 5, 5]) True\n",
            "layer1.0.bias torch.Size([32]) True\n",
            "layer2.0.weight torch.Size([64, 32, 5, 5]) True\n",
            "layer2.0.bias torch.Size([64]) True\n",
            "fc1.weight torch.Size([1000, 3136]) True\n",
            "fc1.bias torch.Size([1000]) True\n",
            "fc2.weight torch.Size([3, 1000]) True\n",
            "fc2.bias torch.Size([3]) True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xi2-TsIZtGCi",
        "outputId": "74be56c3-05e9-48e1-a84b-92b3240f64b6"
      },
      "source": [
        "# Training the model\r\n",
        "totalsteps = len(train_loader)\r\n",
        "losslist = []\r\n",
        "accuracylist = []\r\n",
        "num_epochs = 100\r\n",
        "for epoch in range(num_epochs):\r\n",
        "  for i, (images, labels) in enumerate(train_loader):\r\n",
        "    images, labels = images.to(device), labels.to(device)\r\n",
        "    # FORWARD PROP, model(images) automatically calls forward\r\n",
        "    # print(labels)\r\n",
        "    outputs = model(images)\r\n",
        "    # labels = torch.tensor(labels, dtype=torch.long, device=device)\r\n",
        "    # print(outputs, labels)\r\n",
        "    # loss = criterion(outputs, labels)\r\n",
        "    # print(outputs, labels)\r\n",
        "    loss = criterion(outputs, torch.nn.functional.one_hot(labels.long(), num_classes=3).to(torch.float32))\r\n",
        "\r\n",
        "    losslist.append(loss.item())\r\n",
        "\r\n",
        "    # BACK PROP\r\n",
        "    # make the gradients zero\r\n",
        "    optimizer.zero_grad() \r\n",
        "    # perform the backward propagation and get the gradients\r\n",
        "    loss.backward()\r\n",
        "    # adam optimizer training step . We use the gradients in this step\r\n",
        "    optimizer.step()\r\n",
        "\r\n",
        "    # Accuracy\r\n",
        "    # Note we take batch_size amounts of y's at a time\r\n",
        "    total = labels.size(0)\r\n",
        "    # print(outputs, outputs.data)\r\n",
        "    predicted = torch.max(outputs.data,1)[1]\r\n",
        "    # print(outputs)\r\n",
        "    correct = (predicted == labels).sum().item()\r\n",
        "    accuracy = correct / total\r\n",
        "    # accuracylist.append(accuracy)\r\n",
        "\r\n",
        "    # item() is used for getting the scalar from a tensor\r\n",
        "    if((i + 1) % 50 == 0):\r\n",
        "    # if(True):\r\n",
        "      print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch + 1, num_epochs, i+1, totalsteps, loss.item(),(accuracy)*100 ))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/100], Step [50/63], Loss: 0.2294, Accuracy: 33.59%\n",
            "Epoch [2/100], Step [50/63], Loss: 0.2253, Accuracy: 29.69%\n",
            "Epoch [3/100], Step [50/63], Loss: 0.2187, Accuracy: 41.41%\n",
            "Epoch [4/100], Step [50/63], Loss: 0.2189, Accuracy: 43.75%\n",
            "Epoch [5/100], Step [50/63], Loss: 0.2260, Accuracy: 33.59%\n",
            "Epoch [6/100], Step [50/63], Loss: 0.2236, Accuracy: 35.16%\n",
            "Epoch [7/100], Step [50/63], Loss: 0.2187, Accuracy: 42.97%\n",
            "Epoch [8/100], Step [50/63], Loss: 0.2234, Accuracy: 36.72%\n",
            "Epoch [9/100], Step [50/63], Loss: 0.2238, Accuracy: 39.84%\n",
            "Epoch [10/100], Step [50/63], Loss: 0.2204, Accuracy: 42.19%\n",
            "Epoch [11/100], Step [50/63], Loss: 0.2214, Accuracy: 39.06%\n",
            "Epoch [12/100], Step [50/63], Loss: 0.2231, Accuracy: 35.16%\n",
            "Epoch [13/100], Step [50/63], Loss: 0.2231, Accuracy: 33.59%\n",
            "Epoch [14/100], Step [50/63], Loss: 0.2203, Accuracy: 39.06%\n",
            "Epoch [15/100], Step [50/63], Loss: 0.2191, Accuracy: 42.19%\n",
            "Epoch [16/100], Step [50/63], Loss: 0.2212, Accuracy: 38.28%\n",
            "Epoch [17/100], Step [50/63], Loss: 0.2233, Accuracy: 33.59%\n",
            "Epoch [18/100], Step [50/63], Loss: 0.2208, Accuracy: 39.06%\n",
            "Epoch [19/100], Step [50/63], Loss: 0.2195, Accuracy: 41.41%\n",
            "Epoch [20/100], Step [50/63], Loss: 0.2215, Accuracy: 37.50%\n",
            "Epoch [21/100], Step [50/63], Loss: 0.2250, Accuracy: 32.81%\n",
            "Epoch [22/100], Step [50/63], Loss: 0.2173, Accuracy: 45.31%\n",
            "Epoch [23/100], Step [50/63], Loss: 0.2178, Accuracy: 46.88%\n",
            "Epoch [24/100], Step [50/63], Loss: 0.2177, Accuracy: 45.31%\n",
            "Epoch [25/100], Step [50/63], Loss: 0.2221, Accuracy: 36.72%\n",
            "Epoch [26/100], Step [50/63], Loss: 0.2258, Accuracy: 30.47%\n",
            "Epoch [27/100], Step [50/63], Loss: 0.2219, Accuracy: 36.72%\n",
            "Epoch [28/100], Step [50/63], Loss: 0.2208, Accuracy: 38.28%\n",
            "Epoch [29/100], Step [50/63], Loss: 0.2202, Accuracy: 39.84%\n",
            "Epoch [30/100], Step [50/63], Loss: 0.2212, Accuracy: 39.06%\n",
            "Epoch [31/100], Step [50/63], Loss: 0.2187, Accuracy: 42.97%\n",
            "Epoch [32/100], Step [50/63], Loss: 0.2178, Accuracy: 39.84%\n",
            "Epoch [33/100], Step [50/63], Loss: 0.2196, Accuracy: 40.62%\n",
            "Epoch [34/100], Step [50/63], Loss: 0.2214, Accuracy: 40.62%\n",
            "Epoch [35/100], Step [50/63], Loss: 0.2199, Accuracy: 39.84%\n",
            "Epoch [36/100], Step [50/63], Loss: 0.2231, Accuracy: 34.38%\n",
            "Epoch [37/100], Step [50/63], Loss: 0.2237, Accuracy: 34.38%\n",
            "Epoch [38/100], Step [50/63], Loss: 0.2202, Accuracy: 40.62%\n",
            "Epoch [39/100], Step [50/63], Loss: 0.2178, Accuracy: 42.97%\n",
            "Epoch [40/100], Step [50/63], Loss: 0.2195, Accuracy: 42.97%\n",
            "Epoch [41/100], Step [50/63], Loss: 0.2192, Accuracy: 42.19%\n",
            "Epoch [42/100], Step [50/63], Loss: 0.2231, Accuracy: 33.59%\n",
            "Epoch [43/100], Step [50/63], Loss: 0.2198, Accuracy: 42.97%\n",
            "Epoch [44/100], Step [50/63], Loss: 0.2245, Accuracy: 32.81%\n",
            "Epoch [45/100], Step [50/63], Loss: 0.2194, Accuracy: 41.41%\n",
            "Epoch [46/100], Step [50/63], Loss: 0.2253, Accuracy: 30.47%\n",
            "Epoch [47/100], Step [50/63], Loss: 0.2182, Accuracy: 45.31%\n",
            "Epoch [48/100], Step [50/63], Loss: 0.2209, Accuracy: 39.06%\n",
            "Epoch [49/100], Step [50/63], Loss: 0.2176, Accuracy: 43.75%\n",
            "Epoch [50/100], Step [50/63], Loss: 0.2226, Accuracy: 35.94%\n",
            "Epoch [51/100], Step [50/63], Loss: 0.2269, Accuracy: 33.59%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-4c5ba2d097d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# adam optimizer training step . We use the gradients in this step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m                    )\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \"\"\"\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "cOQbHtq2Jxd9",
        "outputId": "92619402-6d6e-4c1a-d536-93b7c4f498d0"
      },
      "source": [
        "plt.plot(losslist)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6391f6f048>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "Mtrh_CSb-7VW",
        "outputId": "69ab5ce2-3343-4a71-de3b-7a83f88241c3"
      },
      "source": [
        "model.eval()\r\n",
        "with torch.no_grad():\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "  # The following loop runs only for 1 time as the batch size for test loader is the size of number of test images only\r\n",
        "  for images, labels in test_loader:\r\n",
        "    images, labels = images.to(device), labels.to(device)\r\n",
        "    outputs = model(images)\r\n",
        "    predicted = torch.max(outputs.data,1)[1]\r\n",
        "    categories = [i for i in range(3)]\r\n",
        "    confmat, df, macrof1, acc, plt = performance_metrics_multiclass(predicted.to('cpu').numpy(), labels.to('cpu').numpy(), num_class=3)\r\n",
        "    print(confmat)\r\n",
        "    print(df)\r\n",
        "    print('macroF1 = {}, accuracy = {}'.format(macrof1, acc))\r\n",
        "    total += labels.size(0)\r\n",
        "    correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "  print('Test Accuracy for {} test images = {} %'.format(len(test_loader.dataset) ,(correct/total)*100))\r\n",
        "\r\n",
        "  # torch.save(model.state_dict(), './MODEL_STORE/MNIST_conve_nets.ckpt')\r\n",
        "\r\n",
        "\r\n",
        "  ##Performance metrics\r\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:18: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(3, 3)\n",
            "[[0.      0.85206 0.     ]\n",
            " [0.      1.      0.     ]\n",
            " [0.      0.99289 0.     ]]\n",
            "   class  Precision  Recall       F1\n",
            "0    0.0        NaN     0.0      NaN\n",
            "1    1.0     0.3515     1.0  0.52016\n",
            "2    2.0        NaN     0.0      NaN\n",
            "macroF1 = 0.52016, accuracy = 0.3515\n",
            "Test Accuracy for 2000 test images = 35.15 %\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n46RlsDS-7pd"
      },
      "source": [
        "# SVM as classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxhz44ZCvK6h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1rOoyjz1ci2",
        "outputId": "27a54ead-c0d2-4f49-eeaf-b7be69574994"
      },
      "source": [
        "for cluster in clusters:\r\n",
        "  print('FOR {} Clusters'.format(cluster))\r\n",
        "\r\n",
        "  y = kmeans_svhn_tsne[cluster].labels_\r\n",
        "\r\n",
        "  X_train_, y_train_ = svhn_tsne[0:8000], y[0:8000]\r\n",
        "  X_test_, y_test_ = svhn_tsne[8000:], y[8000:]\r\n",
        "\r\n",
        "  clf = svm.SVC(kernel='poly', degree = 1, C = 1)\r\n",
        "  clf.fit(X_train_, y_train_)\r\n",
        "\r\n",
        "  y_pred_test = clf.predict(X_test_)\r\n",
        "  y_pred_train = clf.predict(X_train_)\r\n",
        "\r\n",
        "  print(classification_report(y_test_, y_pred_test, digits = 4))\r\n",
        "  print(classification_report(y_train_, y_pred_train, digits = 4))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FOR 3 Clusters\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9967    0.9950    0.9958       599\n",
            "           1     0.9958    1.0000    0.9979       703\n",
            "           2     1.0000    0.9971    0.9986       698\n",
            "\n",
            "    accuracy                         0.9975      2000\n",
            "   macro avg     0.9975    0.9974    0.9974      2000\n",
            "weighted avg     0.9975    0.9975    0.9975      2000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9971    0.9913    0.9942      2417\n",
            "           1     0.9918    0.9993    0.9956      3029\n",
            "           2     0.9996    0.9961    0.9978      2554\n",
            "\n",
            "    accuracy                         0.9959      8000\n",
            "   macro avg     0.9962    0.9956    0.9959      8000\n",
            "weighted avg     0.9959    0.9959    0.9959      8000\n",
            "\n",
            "FOR 5 Clusters\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9636    0.9973    0.9802       372\n",
            "           1     0.9922    1.0000    0.9961       381\n",
            "           2     0.9974    0.9898    0.9936       392\n",
            "           3     1.0000    0.9955    0.9977       444\n",
            "           4     1.0000    0.9732    0.9864       411\n",
            "\n",
            "    accuracy                         0.9910      2000\n",
            "   macro avg     0.9907    0.9912    0.9908      2000\n",
            "weighted avg     0.9912    0.9910    0.9910      2000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9784    0.9894    0.9839      1512\n",
            "           1     0.9885    1.0000    0.9942      1545\n",
            "           2     0.9959    0.9931    0.9945      1458\n",
            "           3     0.9969    0.9964    0.9967      1944\n",
            "           4     0.9980    0.9786    0.9882      1541\n",
            "\n",
            "    accuracy                         0.9918      8000\n",
            "   macro avg     0.9915    0.9915    0.9915      8000\n",
            "weighted avg     0.9918    0.9918    0.9917      8000\n",
            "\n",
            "FOR 10 Clusters\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9947    0.9742    0.9844       194\n",
            "           1     1.0000    0.9736    0.9866       227\n",
            "           2     0.9745    0.9896    0.9820       193\n",
            "           3     0.9878    1.0000    0.9939       243\n",
            "           4     0.9855    1.0000    0.9927       204\n",
            "           5     1.0000    0.9493    0.9740       138\n",
            "           6     0.9724    1.0000    0.9860       247\n",
            "           7     1.0000    0.9885    0.9942       174\n",
            "           8     1.0000    1.0000    1.0000       179\n",
            "           9     0.9755    0.9900    0.9827       201\n",
            "\n",
            "    accuracy                         0.9880      2000\n",
            "   macro avg     0.9890    0.9865    0.9876      2000\n",
            "weighted avg     0.9882    0.9880    0.9880      2000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9906    0.9859    0.9882       852\n",
            "           1     0.9911    0.9900    0.9905       897\n",
            "           2     0.9691    0.9805    0.9748       768\n",
            "           3     0.9883    0.9988    0.9935       845\n",
            "           4     0.9807    0.9967    0.9887       920\n",
            "           5     0.9905    0.9738    0.9821       534\n",
            "           6     0.9727    0.9990    0.9857       964\n",
            "           7     0.9853    0.9749    0.9801       756\n",
            "           8     0.9959    0.9759    0.9858       746\n",
            "           9     0.9957    0.9652    0.9802       718\n",
            "\n",
            "    accuracy                         0.9854      8000\n",
            "   macro avg     0.9860    0.9841    0.9849      8000\n",
            "weighted avg     0.9855    0.9854    0.9854      8000\n",
            "\n",
            "FOR 15 Clusters\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9700    1.0000    0.9848        97\n",
            "           1     0.9845    0.9922    0.9883       128\n",
            "           2     0.9852    1.0000    0.9925       133\n",
            "           3     0.9430    0.9739    0.9582       153\n",
            "           4     0.9815    1.0000    0.9907       159\n",
            "           5     0.9586    0.9858    0.9720       141\n",
            "           6     0.9397    0.9732    0.9561       112\n",
            "           7     0.9878    1.0000    0.9939       162\n",
            "           8     0.9756    0.9524    0.9639       126\n",
            "           9     0.9632    0.9562    0.9597       137\n",
            "          10     1.0000    0.9352    0.9665       108\n",
            "          11     1.0000    0.9680    0.9837       125\n",
            "          12     1.0000    0.9917    0.9958       120\n",
            "          13     0.9850    0.9776    0.9813       134\n",
            "          14     1.0000    0.9576    0.9783       165\n",
            "\n",
            "    accuracy                         0.9780      2000\n",
            "   macro avg     0.9783    0.9776    0.9777      2000\n",
            "weighted avg     0.9784    0.9780    0.9780      2000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9783    0.9880    0.9831       501\n",
            "           1     0.9826    0.9941    0.9883       510\n",
            "           2     0.9883    1.0000    0.9941       590\n",
            "           3     0.9674    0.9818    0.9745       604\n",
            "           4     0.9909    0.9801    0.9855       554\n",
            "           5     0.9552    0.9884    0.9715       604\n",
            "           6     0.9762    0.9889    0.9825       540\n",
            "           7     0.9691    0.9984    0.9836       629\n",
            "           8     0.9894    0.9649    0.9770       484\n",
            "           9     0.9751    0.9716    0.9734       564\n",
            "          10     0.9977    0.9562    0.9765       457\n",
            "          11     0.9866    0.9694    0.9779       457\n",
            "          12     1.0000    0.9978    0.9989       450\n",
            "          13     0.9873    0.9510    0.9688       490\n",
            "          14     0.9892    0.9753    0.9822       566\n",
            "\n",
            "    accuracy                         0.9811      8000\n",
            "   macro avg     0.9822    0.9804    0.9812      8000\n",
            "weighted avg     0.9813    0.9811    0.9811      8000\n",
            "\n",
            "FOR 20 Clusters\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     1.0000    0.9681    0.9838        94\n",
            "           1     0.9903    1.0000    0.9951       102\n",
            "           2     0.9744    0.9661    0.9702       118\n",
            "           3     0.9200    0.9583    0.9388        96\n",
            "           4     0.9099    1.0000    0.9528       101\n",
            "           5     1.0000    0.9914    0.9957       116\n",
            "           6     0.9606    0.9919    0.9760       123\n",
            "           7     0.9487    1.0000    0.9737       111\n",
            "           8     1.0000    0.9714    0.9855       105\n",
            "           9     0.9833    0.9672    0.9752        61\n",
            "          10     0.9703    0.9899    0.9800        99\n",
            "          11     1.0000    0.9130    0.9545        69\n",
            "          12     0.9931    0.9862    0.9896       145\n",
            "          13     0.9727    0.9727    0.9727       110\n",
            "          14     0.9894    1.0000    0.9947        93\n",
            "          15     0.9574    0.9278    0.9424        97\n",
            "          16     0.9832    0.9915    0.9873       118\n",
            "          17     1.0000    0.8966    0.9455        87\n",
            "          18     1.0000    0.9759    0.9878        83\n",
            "          19     0.9726    0.9861    0.9793        72\n",
            "\n",
            "    accuracy                         0.9750      2000\n",
            "   macro avg     0.9763    0.9727    0.9740      2000\n",
            "weighted avg     0.9758    0.9750    0.9750      2000\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9756    0.9651    0.9704       373\n",
            "           1     0.9581    1.0000    0.9786       434\n",
            "           2     0.9761    0.9813    0.9787       375\n",
            "           3     0.9767    0.9706    0.9737       476\n",
            "           4     0.9525    1.0000    0.9757       421\n",
            "           5     1.0000    0.9884    0.9942       431\n",
            "           6     0.9656    0.9883    0.9768       426\n",
            "           7     0.9659    1.0000    0.9826       481\n",
            "           8     1.0000    0.9617    0.9805       392\n",
            "           9     0.9930    0.9726    0.9827       292\n",
            "          10     0.9607    0.9978    0.9789       465\n",
            "          11     1.0000    0.9620    0.9806       342\n",
            "          12     0.9829    0.9767    0.9798       472\n",
            "          13     0.9925    0.9754    0.9839       406\n",
            "          14     0.9882    0.9882    0.9882       340\n",
            "          15     0.9830    0.9878    0.9854       410\n",
            "          16     0.9848    0.9701    0.9774       402\n",
            "          17     1.0000    0.9644    0.9819       393\n",
            "          18     0.9969    0.9846    0.9907       324\n",
            "          19     0.9762    0.9507    0.9633       345\n",
            "\n",
            "    accuracy                         0.9801      8000\n",
            "   macro avg     0.9814    0.9793    0.9802      8000\n",
            "weighted avg     0.9805    0.9801    0.9801      8000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwJ_J5Ym90qr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}